input {
  beats {
    port => "10001"
  }
}

filter {
  if [agent][type] == "metricbeat" {
    # Initial parse flag
    mutate {
      add_field => {
        "FLAG_DEBUG" => false
        "FLAG_PARSED" => false
      }
    }

    # Set agent type
    mutate {
      add_field => { "agent_type" => "custom" }
    }

    # Change timezone
    #date { match => [ "@timestamp", "ISO8601" ] timezone => "UTC" }

    # Get epoch from timestamp object
    ruby { code => "event.set('epoch', event.get('@timestamp').to_i * 1000)" }

    # Set instance name
    mutate { add_field => { "instance_name" => "%{[host][name]}" } }

    # Set project name
    mutate { add_field => { "project_name" => "metric_if_system" } }

    # Get sampling interval
    ruby { code => "event.set('sampling_interval', event.get('[metricset][period]').to_i / 1000)" }

    # Get metric data
    ruby {
      init => '
        require "set"
        require "json"
        MEGABYTE = 1024.0 * 1024.0
        @disk_devices = Set.new
        @network_devices = Set.new
        @prev_networkin_bytes = Hash.new { |hash, key| hash[key] = {} }
        @prev_networkout_bytes = Hash.new { |hash, key| hash[key] = {} }
      '
      code => '
        data = {}
        dataset = event.get("[event][dataset]")
        instance = event.get("instance_name")
        interval = event.get("sampling_interval")
        offset = 0

        if dataset == "system.cpu"
          data["CPU%[#{instance}]"] = event.get("[system][cpu][total][pct]").to_s
        elsif dataset == "system.memory"
          data["Memory%[#{instance}]"] = event.get("[system][memory][used][pct]").to_s
        elsif dataset == "system.fsstat"
          value = event.get("[system][fsstat][total_size][used]") / event.get("[system][fsstat][total_size][total]").to_f
          data["Filesystem%[#{instance}]"] = "%.10f" % value
        elsif dataset == "system.diskio"
          device = event.get("[system][diskio][name]")
          @disk_devices << device
          offset = @disk_devices.find_index(device)
          value = event.get("[system][diskio][iostat][read][per_sec][bytes]") / MEGABYTE
          data["Diskio Read MB/s (#{device})[#{instance}]"] = "%.10f" % value
          value = event.get("[system][diskio][iostat][write][per_sec][bytes]") / MEGABYTE
          data["Diskio Write MB/s (#{device})[#{instance}]"] = "%.10f" % value
        elsif dataset == "system.network"
          device = event.get("[system][network][name]")
          @network_devices << device
          offset = @network_devices.find_index(device)
          current_networkin_bytes = event.get("[system][network][in][bytes]")
          current_networkout_bytes = event.get("[system][network][out][bytes]")
          if @prev_networkin_bytes[instance][device] and @prev_networkout_bytes[instance][device]
            value = (current_networkin_bytes - @prev_networkin_bytes[instance][device]).abs() / MEGABYTE / interval
            data["Network In MB/s (#{device})[#{instance}]"] = "%.10f" % value
            value = (current_networkout_bytes - @prev_networkout_bytes[instance][device]).abs() / MEGABYTE / interval
            data["Network Out MB/s (#{device})[#{instance}]"] = "%.10f" % value
          end
          @prev_networkin_bytes[instance][device] = current_networkin_bytes
          @prev_networkout_bytes[instance][device] = current_networkout_bytes
        elsif dataset == "system.load"
          data["Load Average 1m[#{instance}]"] = event.get("[system][load][1]").to_s
          data["Load Average 5m[#{instance}]"] = event.get("[system][load][5]").to_s
          data["Load Average 15m[#{instance}]"] = event.get("[system][load][15]").to_s
        elsif dataset == "system.process.summary"
          data["Process Total[#{instance}]"] = event.get("[system][process][summary][total]").to_s
          data["Process Sleeping[#{instance}]"] = event.get("[system][process][summary][sleeping]").to_s
          data["Process Running[#{instance}]"] = event.get("[system][process][summary][running]").to_s
          data["Process Idle[#{instance}]"] = event.get("[system][process][summary][idle]").to_s
          data["Process Stopped[#{instance}]"] = event.get("[system][process][summary][stopped]").to_s
          data["Process Zombie[#{instance}]"] = event.get("[system][process][summary][zombie]").to_s
          data["Process Dead[#{instance}]"] = event.get("[system][process][summary][dead]").to_s
        end

        if not data.empty?
          # Insert timestamp at the beginning
          event.set("metric_data", {"timestamp" => (event.get("epoch") + offset).to_s}.merge(data).to_json)
        end
      '
    }

    # Update parse flag
    if ![epoch] or ![instance_name] or ![project_name] or ![metric_data] {
      mutate { update => { "FLAG_PARSED" => false }}
    } else {
      mutate { update => { "FLAG_PARSED" => true }}
    }
  }
}

output {
  if [FLAG_DEBUG] == "true" {
    stdout { codec => rubydebug }
  } else if [FLAG_PARSED] {
    if [FLAG_PARSED] == "false" {
      stdout { codec => line { format => "[%{@timestamp}] Parsing error, skip this event from %{instance_name}." } }
    } else {
      stdout { codec => line { format => "[%{@timestamp}] Posting data to project: %{project_name}" }}

      #-- set url, username, licensekey here
      http {
        url => "http://127.0.0.1:8080/customprojectrawdata"
        http_method => post
        format => form
        mapping => {
          "userName" => "user"
          "licenseKey" => "a333bd39662ad1edf64e99e97e4b776109827234"
          "projectName" => "%{project_name}"
          "agentType" => "%{agent_type}"
          "metricData" => "[%{metric_data}]"
          "instanceName" => "%{instance_name}"
          "samplingInterval" => "%{sampling_interval}"
        }
      }
    }
  }
}

